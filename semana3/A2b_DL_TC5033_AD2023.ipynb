{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TC 5033\n",
    "## Deep Learning\n",
    "## Convolutional Neural Networks\n",
    "<br>\n",
    "\n",
    "#### Activity 2b: Building a CNN for CIFAR10 dataset with PyTorch\n",
    "<br>\n",
    "\n",
    "- Objective\n",
    "\n",
    "    The main goal of this activity is to further your understanding of Convolutional Neural Networks (CNNs) by building one using PyTorch. You will apply this architecture to the famous CIFAR10 dataset, taking what you've learned from the guide code that replicated the Fully Connected model in PyTorch (Activity 2a).\n",
    "\n",
    "- Instructions\n",
    "    This activity requires submission in teams of 3 or 4 members. Submissions from smaller or larger teams will not be accepted unless prior approval has been granted (only due to exceptional circumstances). While teamwork is encouraged, each member is expected to contribute individually to the assignment. The final submission should feature the best arguments and solutions from each team member. Only one person per team needs to submit the completed work, but it is imperative that the names of all team members are listed in a Markdown cell at the very beginning of the notebook (either the first or second cell). Failure to include all team member names will result in the grade being awarded solely to the individual who submitted the assignment, with zero points given to other team members (no exceptions will be made to this rule).\n",
    "\n",
    "    Understand the Guide Code: Review the guide code from Activity 2a that implemented a Fully Connected model in PyTorch. Note how PyTorch makes it easier to implement neural networks.\n",
    "\n",
    "    Familiarize Yourself with CNNs: Take some time to understand their architecture and the rationale behind using convolutional layers.\n",
    "\n",
    "    Prepare the Dataset: Use PyTorch's DataLoader to manage the dataset. Make sure the data is appropriately preprocessed for a CNN.\n",
    "\n",
    "    Design the CNN Architecture: Create a new architecture that incorporates convolutional layers. Use PyTorch modules like nn.Conv2d, nn.MaxPool2d, and others to build your network.\n",
    "\n",
    "    Training Loop and Backpropagation: Implement the training loop, leveraging PyTorch’s autograd for backpropagation. Keep track of relevant performance metrics.\n",
    "\n",
    "    Analyze and Document: Use Markdown cells to explain your architectural decisions, performance results, and any challenges you faced. Compare this model with your previous Fully Connected model in terms of performance and efficiency.\n",
    "\n",
    "- Evaluation Criteria\n",
    "\n",
    "    - Understanding of CNN architecture and its application to the CIFAR10 dataset\n",
    "    - Code Readability and Comments\n",
    "    - Appropriateness and efficiency of the chosen CNN architecture\n",
    "    - Correct implementation of Traning Loop and Accuracy Function\n",
    "    - Model's performance metrics on the CIFAR10 dataset (at least 65% accuracy)\n",
    "    - Quality of Markdown documentation\n",
    "\n",
    "- Submission\n",
    "\n",
    "Submit via Canvas your Jupyter Notebook with the CNN implemented in PyTorch. Your submission should include well-commented code and Markdown cells that provide a comprehensive view of your design decisions, performance metrics, and learnings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrantes del equipo:\n",
    "\n",
    "*   Oscar Villa Cardenas - A01794052\n",
    "*   Diego Alberto Olarte Mira - A01794028\n",
    "*   Erick Alexei Cambray Servín - A01794243\n",
    "*   Andres Javier Galindo Vargas - A01793927"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as T\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Cifar10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = './data/'\n",
    "NUM_TRAIN = 50000\n",
    "NUM_VAL = 5000\n",
    "NUM_TEST = 5000\n",
    "MINIBATCH_SIZE = 64\n",
    "\n",
    "transform_cifar = T.Compose([\n",
    "                T.ToTensor(),\n",
    "                T.Normalize([0.491, 0.482, 0.447], [0.247, 0.243, 0.261])\n",
    "            ])\n",
    "\n",
    "# Train dataset\n",
    "cifar10_train = datasets.CIFAR10(DATA_PATH, train=True, download=True,\n",
    "                             transform=transform_cifar)\n",
    "train_loader = DataLoader(cifar10_train, batch_size=MINIBATCH_SIZE,\n",
    "                          sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)))\n",
    "#Validation set\n",
    "cifar10_val = datasets.CIFAR10(DATA_PATH, train=False, download=True,\n",
    "                           transform=transform_cifar)\n",
    "val_loader = DataLoader(cifar10_val, batch_size=MINIBATCH_SIZE,\n",
    "                        sampler=sampler.SubsetRandomSampler(range(NUM_VAL)))\n",
    "#Test set\n",
    "cifar10_test = datasets.CIFAR10(DATA_PATH, train=False, download=True,\n",
    "                            transform=transform_cifar)\n",
    "test_loader = DataLoader(cifar10_test, batch_size=MINIBATCH_SIZE,\n",
    "                        sampler=sampler.SubsetRandomSampler(range(NUM_VAL, len(cifar10_test))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader.batch_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (x, y) in enumerate(train_loader):\n",
    "    print(x, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using  GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mostrar imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = test_loader.dataset.classes\n",
    "def plot_figure(image):\n",
    "    plt.imshow(np.transpose(image,(1,2,0)))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "rnd_sample_idx = np.random.randint(len(test_loader))\n",
    "print(f'La imagen muestreada representa un: {classes[test_loader.dataset[rnd_sample_idx][1]]}')\n",
    "image = test_loader.dataset[rnd_sample_idx][0]\n",
    "image = (image - image.min()) / (image.max() -image.min() )\n",
    "plot_figure(image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class visualization\n",
    "It will create a gridplot to see the 10 classes and examples of each one of the classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cifar10_grid():\n",
    "    classes = test_loader.dataset.classes\n",
    "    total_samples = 8\n",
    "    plt.figure(figsize=(15,15))\n",
    "    for label, sample in enumerate(classes):\n",
    "        class_idxs = np.flatnonzero(label == np.array(test_loader.dataset.targets))\n",
    "        sample_idxs = np.random.choice(class_idxs, total_samples, replace = False)\n",
    "        for i, idx in enumerate(sample_idxs):\n",
    "            plt_idx = i*len(classes) + label + 1\n",
    "            plt.subplot(total_samples, len(classes), plt_idx)\n",
    "            plt.imshow(test_loader.dataset.data[idx])\n",
    "            plt.axis('off')\n",
    "\n",
    "            if i == 0: plt.title(sample)\n",
    "    plt.show()\n",
    "\n",
    "plot_cifar10_grid()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy\n",
    "This function calculates the accuracy of a model on a given data loader.\n",
    "\n",
    "To calculate the accuracy, we first set the model to evaluation mode. This ensures that the model does not calculate gradients during the accuracy calculation. We then move the model to the desired device (CPU or GPU).\n",
    "\n",
    "Next, we iterate over the data loader and calculate the accuracy for each batch. For each batch, we first move the data and labels to the same device as the model. We then pass the data to the model and get the predicted scores. We then get the predicted labels by taking the maximum score for each batch element. Finally, we compare the predicted labels to the true labels and update the number of correct and total predictions.\n",
    "\n",
    "After iterating over the entire data loader, we calculate the overall accuracy by dividing the number of correct predictions by the total number of predictions.\n",
    "\n",
    "This function can be used to evaluate the accuracy of a model on a held-out test set. It can also be used to track the accuracy of a model during training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def accuracy(model, loader):\n",
    "  \"\"\"Calculates the accuracy of a model on a given data loader.\n",
    "\n",
    "  Args:\n",
    "    model: A PyTorch model.\n",
    "    loader: A PyTorch data loader.\n",
    "\n",
    "  Returns:\n",
    "    The accuracy of the model on the given data loader.\n",
    "  \"\"\"\n",
    "\n",
    "  num_correct = 0\n",
    "  num_total = 0\n",
    "  model.eval()\n",
    "  model = model.to(device=device)\n",
    "  with torch.no_grad():\n",
    "    for xi, yi in loader:\n",
    "      xi = xi.to(device=device, dtype=torch.float32)\n",
    "      yi = yi.to(device=device, dtype=torch.long)\n",
    "      scores = model(xi)\n",
    "      _, pred = scores.max(dim=1)\n",
    "      num_correct += (pred == yi).sum()\n",
    "      num_total += pred.size(0)\n",
    "  return float(num_correct) / num_total\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop\n",
    "\n",
    "This function trains a PyTorch model on a given training dataset for a specified number of epochs. The function takes three arguments:\n",
    "\n",
    "model: A PyTorch model.\n",
    "optimiser: A PyTorch optimizer.\n",
    "epochs: The number of epochs to train the model for.\n",
    "The function works as follows:\n",
    "\n",
    "- It moves the model to the desired device (CPU or GPU).\n",
    "- It starts a loop to iterate over the training dataset for the specified number of epochs.\n",
    "- For each epoch, it iterates over the training dataset and performs the following steps:\n",
    "- It sets the model to training mode.\n",
    "- Moves the data and labels to the same device as the model.\n",
    "- Runs the model on the data and calculates the predicted scores.\n",
    "- Calculates the loss function (cross-entropy in this case).\n",
    "- Sets the gradients to zero.\n",
    "- Backpropagates the loss through the network to calculate the gradients for all the parameters.\n",
    "- Updates the model parameters using the optimizer.\n",
    "After each epoch, the function calculates the accuracy of the model on the validation dataset.\n",
    "Finally, the function returns the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimiser, epochs=100):\n",
    "    \"\"\"Trains a PyTorch model on a given training dataset for a specified number of epochs.\n",
    "\n",
    "    Args:\n",
    "        model: A PyTorch model.\n",
    "        optimiser: A PyTorch optimizer.\n",
    "        epochs: The number of epochs to train the model for.\n",
    "\n",
    "    Returns:\n",
    "        The trained model.\n",
    "    \"\"\"\n",
    "\n",
    "    model = model.to(device=device)\n",
    "    for epoch in range(epochs):\n",
    "        for i, (xi, yi) in enumerate(train_loader):\n",
    "            model.train()\n",
    "            xi = xi.to(device=device, dtype=torch.float32)\n",
    "            yi = yi.to(device=device, dtype=torch.long)\n",
    "            scores = model(xi)\n",
    "            cost = F.cross_entropy(input=scores, target=yi)\n",
    "            optimiser.zero_grad()\n",
    "            cost.backward()\n",
    "            optimiser.step()\n",
    "\n",
    "        acc = accuracy(model, val_loader)\n",
    "        print(f'Epoch: {epoch}, costo: {cost.item()}, accuracy: {acc},')\n",
    "\n",
    "    # return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear model\n",
    "To test the base model.\n",
    "\n",
    "This code creates a linear neural network model and an optimizer. The model has three layers: an input layer, a hidden layer, and an output layer. The input layer has 32323 neurons, which is the number of pixels in a color image. The hidden layer has 256 neurons. The output layer has 10 neurons, which is the number of classes in the dataset.\n",
    "\n",
    "The optimizer is Adam, which is a popular optimizer for training deep learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(hidden1=256, hidden=256, lr=0.001, epochs=10):\n",
    "    \"\"\"Creates a linear neural network model and an optimizer.\n",
    "\n",
    "    Args:\n",
    "        hidden1: The number of neurons in the hidden layer.\n",
    "        hidden: The number of neurons in the hidden layer.\n",
    "        lr: The learning rate.\n",
    "        epochs: The number of epochs to train the model for.\n",
    "\n",
    "    Returns:\n",
    "        A tuple containing the model and the optimizer.\n",
    "    \"\"\"\n",
    "\n",
    "    model1 = nn.Sequential(\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(in_features=32*32*3, out_features=hidden1), nn.ReLU(),\n",
    "        nn.Linear(in_features=hidden1, out_features=hidden), nn.ReLU(),\n",
    "        nn.Linear(in_features=hidden, out_features=10))\n",
    "\n",
    "    optimiser = torch.optim.Adam(model1.parameters(), lr=lr)\n",
    "\n",
    "    return model1, optimiser\n",
    "\n",
    "model1, optimiser = create_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "train(model1, optimiser, epochs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential CNN\n",
    "\n",
    "- The model has two convolutional layers, a max pooling layer, and a fully connected layer. \n",
    "- First convolutional layer has 16 filters and the second convolutional layer has 32 filters. \n",
    "- Max pooling layer downsamples the output of the second convolutional layer by a factor of 2. The fully connected layer has 10 neurons, which is the number of classes in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_model(channel1=16, channel2=32, epochs=10, lr=0.0001):\n",
    "    \"\"\"Creates a convolutional neural network model and an optimizer.\n",
    "\n",
    "    Args:\n",
    "        channel1: The number of filters in the first convolutional layer.\n",
    "        channel2: The number of filters in the second convolutional layer.\n",
    "        epochs: The number of epochs to train the model for.\n",
    "        lr: The learning rate.\n",
    "\n",
    "    Returns:\n",
    "        A tuple containing the model and the optimizer.\n",
    "    \"\"\"\n",
    "\n",
    "    modelCNN1 = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=3, out_channels=channel1,\n",
    "                        kernel_size=3, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(in_channels=channel1, out_channels=channel2,\n",
    "                        kernel_size= 3, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(2, 2),\n",
    "                nn.Flatten(),\n",
    "                nn.Linear(in_features=16*16*channel2, out_features=10)\n",
    "            )\n",
    "\n",
    "    optimiser = torch.optim.Adam(modelCNN1.parameters(), lr)\n",
    "\n",
    "    return modelCNN1, optimiser\n",
    "\n",
    "modelCNN1, optimiser = create_cnn_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(modelCNN1, optimiser, epochs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This lambda function takes two parameters, channel1 and channel2, and returns a nn.Conv2d() layer with the specified input and output channels, a kernel size of 3, and padding of 1.\n",
    "\n",
    "Lambda functions are anonymous functions that can be created on the fly. They are useful for creating concise and expressive code. In this case, the lambda function is used to reduce the amount of duplicate code in the main function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_k_3 = lambda channel1, channel2: nn.Conv2d(channel1, channel2, kernel_size=3, padding=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This class is built on top of the PyTorch framework, specifically extending the \"nn.Module\" class. \n",
    "The constructor of the \"CNN_class4\" class accepts three parameters: \"in_channels\" representing the number of input channels, \"channel1\" representing the output channels for the first convolutional layer and the input channels for the second convolutional layer, and \"channel2\" representing the output channels for the second convolutional layer. \n",
    "\n",
    "Inside the constructor, it initializes two convolutional layers, applies batch normalization to their outputs, and sets up a max-pooling operation with a 2x2 kernel. \n",
    "The \"forward\" method overrides the parent class's forward function and defines the sequence of operations: applying the first convolutional layer, normalizing and applying the ReLU activation function, then applying the second convolutional layer, normalizing and applying ReLU again, followed by max-pooling. This class facilitates the creation and customization of a CNN architecture for image processing tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_class4(nn.Module):\n",
    "    \"\"\"\n",
    "    A PyTorch-based Convolutional Neural Network (CNN) class with customizable architecture.\n",
    "\n",
    "    Args:\n",
    "        in_channels (int): Number of input channels.\n",
    "        channel1 (int): Number of output channels for the first convolutional layer and input channels for the second layer.\n",
    "        channel2 (int): Number of output channels for the second convolutional layer.\n",
    "\n",
    "    Attributes:\n",
    "        conv1 (nn.Module): First convolutional layer.\n",
    "        bn1 (nn.Module): Batch normalization layer for the first convolutional layer.\n",
    "        conv2 (nn.Module): Second convolutional layer.\n",
    "        bn2 (nn.Module): Batch normalization layer for the second convolutional layer.\n",
    "        max_pool (nn.Module): Max-pooling operation with a 2x2 kernel and stride 2.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, channel1, channel2):\n",
    "        super().__init__()\n",
    "        self.conv1 = conv_k_3(in_channels, channel1)\n",
    "        self.bn1 = nn.BatchNorm2d(channel1)\n",
    "        self.conv2 = conv_k_3(channel1, channel2)\n",
    "        self.bn2 = nn.BatchNorm2d(channel2)\n",
    "        self.max_pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass through the CNN architecture.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input data.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output of the CNN after applying convolution, batch normalization, ReLU activation,\n",
    "            and max-pooling.\n",
    "        \"\"\"\n",
    "        x = F.relu(self.bn2(self.conv2(F.relu(self.bn1(self.conv1(x))))))\n",
    "        return self.max_pool(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of channels for different layers\n",
    "channel1 = 16  # Channels for the first layer\n",
    "channel2 = 32  # Channels for the second layer\n",
    "channel4 = 128  # Channels for the third and fourth layers\n",
    "\n",
    "epochs = 10\n",
    "lr = 0.001\n",
    "\n",
    "\"\"\"\n",
    "A PyTorch-based neural network model composed of convolutional layers and linear layers for image classification.\n",
    "\n",
    "Architecture:\n",
    "- Layer 1: Input channels = 3, Output channels = channel1.\n",
    "- Layer 2: Input channels = channel2, Output channels = channel2.\n",
    "- Layer 3: Input channels = channel2, Output channels = channel4.\n",
    "- After the convolutional layers, the output is flattened and passed through multiple linear layers\n",
    "    before the final classification layer with 10 output features.\n",
    "\n",
    "Args:\n",
    "    channel1 (int): Number of output channels for the first layer.\n",
    "    channel2 (int): Number of output channels for the second layer.\n",
    "    channel4 (int): Number of output channels for the third and fourth layers.\n",
    "\n",
    "Attributes:\n",
    "    Sequential: PyTorch Sequential container for defining the model's architecture.\n",
    "\"\"\"\n",
    "modelCNN5 = nn.Sequential(\n",
    "    #We initiate an instance of CNN_Class4 and pass the parameters:\n",
    "    #3 as the initial channel of the network\n",
    "    #channel1 as both the out_channel of the first layer as well as the in_channel of the second layer\n",
    "    #channel2 as the out_channel of the second layer\n",
    "    CNN_class4(3,channel1, channel2),\n",
    "    #We initiate another instance of CNN_Class4 and pass the parameters:\n",
    "    #channel2 as the in_channel of the third layer\n",
    "    #channel4 as the out_channel of the the third layer as well as for both the in_channel and out_channel of the forth layer\n",
    "    CNN_class4(channel2, channel4, channel4),\n",
    "    #Then we flatten the output 8x8x64 into a one dimensional vector\n",
    "    nn.Flatten(),\n",
    "    #Lastly we apply the last layer as a linear layer with the params:\n",
    "    #in_features as 8*8*64 because those were the dimensions before the flatten\n",
    "    #out_feature as 10 since we only have 10 classes\n",
    "    nn.Linear(in_features=8*8*channel4, out_features=10)\n",
    ")\n",
    "#We use as optimizer Adam since that is the one we usually use as default\n",
    "optimiser = torch.optim.Adam(modelCNN5.parameters(), lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, costo: 0.7745968103408813, accuracy: 0.6174,\n",
      "Epoch: 1, costo: 0.7720070481300354, accuracy: 0.6956,\n",
      "Epoch: 2, costo: 0.9943426251411438, accuracy: 0.7344,\n",
      "Epoch: 3, costo: 0.7879390716552734, accuracy: 0.7678,\n",
      "Epoch: 4, costo: 1.01791512966156, accuracy: 0.7642,\n",
      "Epoch: 5, costo: 0.6820675730705261, accuracy: 0.7818,\n",
      "Epoch: 6, costo: 0.3965768814086914, accuracy: 0.7702,\n",
      "Epoch: 7, costo: 0.10358618944883347, accuracy: 0.7908,\n",
      "Epoch: 8, costo: 0.16872303187847137, accuracy: 0.79,\n",
      "Epoch: 9, costo: 0.08826413005590439, accuracy: 0.7624,\n"
     ]
    }
   ],
   "source": [
    "train(modelCNN5, optimiser, epochs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "\n",
    "In this project, we have demonstrated how convolutional neural networks (CNNs) can be used for image recognition. The provided code achieved an accuracy of up to 0.79 on a dataset of CIFAR10.\n",
    "\n",
    "This result is promising, as it indicates that CNNs can be used for image classification tasks with a high degree of accuracy. However, it is important to note that this result was obtained with a relatively small dataset. To obtain more accurate results, it would be necessary to use a larger and more diverse dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
